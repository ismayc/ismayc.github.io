# MATH 141
Chester Ismay  

<style type="text/css">
    ol { list-style-type: upper-alpha; }
</style>



## The challenges with the classical method {.build}

The result of a hypothesis test is a probability of the form:

$$ \mathbb{P}(\textrm{ data or  more  extreme } | \ H_0 \textrm{ true }) $$

while most people *think* they're getting

$$ \mathbb{P}(\ H_0 \textrm{ true } | \textrm{ data  or  more  extreme}) $$

How can we go from the former to the latter?


## What we have {.flexbox .vcenter}
<img src="../figs/classical-socks.png" width="800px" />


## What we want {.flexbox .vcenter}
<img src="../figs/bayes-socks.png" width="800px" />


# Bayesian Modeling
## Bayes Rule {.build}

$$\mathbb{P}(A \ | \ B) = \frac{\mathbb{P}(A \textrm{ and } B)}{\mathbb{P}(B)} $$

$$\mathbb{P}(A \ | \ B) = \frac{\mathbb{P}(B \ | \ A) \ \mathbb{P}(A)}{\mathbb{P}(B)} $$

$$\mathbb{P}(model \ | \ data \, or \, more \, extreme) = \frac{\mathbb{P}(data \, or \, more \, extreme\ | \ model) \ \mathbb{P}(model)}{\mathbb{P}(data \, or \, more \, extreme)} $$

What does it mean to think about $\mathbb{P}(model)$?

## Prior distribution {.build .flexbox .vcenter}

A *prior distribution* is a probability distribution for a *parameter* that 
summarizes the information that you have before seeing the data.

<img src="13B_files/figure-html/unnamed-chunk-1-1.png" style="display: block; margin: auto;" />


## Prior on proportion pairs {.flexbox .vcenter .build}

<img src="13B_files/figure-html/unnamed-chunk-2-1.png" style="display: block; margin: auto;" />


## {.flexbox .vcenter}
<img src="../figs/abc1.png" height="550px" />


## {.flexbox .vcenter}
<img src="../figs/abc2.png" height="550px" />


## {.flexbox .vcenter}
<img src="../figs/abc3.png" height="550px" />


## {.flexbox .vcenter}
<img src="../figs/abc4.png" height="550px" />


## {.flexbox .vcenter}
<img src="../figs/abc5.png" height="550px" />


## {.flexbox .vcenter}
<img src="../figs/abc6.png" height="550px" />


## {.flexbox .vcenter}
<img src="../figs/abc7.png" height="550px" />


## Full simulation {.build}




```r
head(sock_sim, 3)
```

```
##   unique pairs n_socks prop_pairs
## 1      3     4      16      0.970
## 2      7     2      33      0.914
## 3      9     1      51      0.929
```

```r
sock_sim %>%
  filter(unique == 11, pairs == 0) %>%
  head(3)
```

```
##   unique pairs n_socks prop_pairs
## 1     11     0      49      0.692
## 2     11     0      37      0.873
## 3     11     0      49      0.815
```


## Proportion of pairs



<img src="13B_files/figure-html/unnamed-chunk-6-1.png" style="display: block; margin: auto;" />


## Number of socks

<img src="13B_files/figure-html/unnamed-chunk-7-1.png" style="display: block; margin: auto;" />


## Karl Broman's Socks {.flexbox .vcenter .build}

<img src="../figs/broman-tweet.png" width="400px" />


## The posterior distribution {.build}

<img src="13B_files/figure-html/unnamed-chunk-8-1.png" style="display: block; margin: auto;" />

* Distribution of a parameter after conditioning on the data
* Synthesis of prior knowledge and observations (data)

### Question: What is your best guess for the number of socks that Karl has?


## Our best guess

<img src="13B_files/figure-html/unnamed-chunk-9-1.png" style="display: block; margin: auto;" />

- The posterior median is 44 socks.


## Karl Broman's Socks {.flexbox .vcenter .build}

<img src="../figs/broman-tweet2.png" width="600px" />

$$ 21 \times 2 + 3 = 45 \textrm{ socks} $$


## Summary {.build}

Bayesian methods . . .

- Require the subjective specification of your prior knowledge
- Provide a posterior distribution on the parameters
- Have strong intuition
- Are computationally expensive


##  {.flexbox .vcenter .build}

<img src="../figs/supernova.png" height="550px" />


