---
title: "MATH 141"
author: "Chester Ismay"
output:
 ioslides_presentation:
   incremental: true
   fig.align: center
   keep_md: yes
   logo: ../figs/griffin.png
   widescreen: yes
subtitle: Inference for a Single Mean
---

```{r setup, include=FALSE}
library(knitr)
options(digits=3)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(ggplot2)
library(oilabs)
```

# Statistics comes from beer?

##
<center>
<img src="../figs/guinness.jpg" width = 350>
</center>


##
<div class="columns-2">
  <center>
<img src="../figs/gosset.jpg" width = 350>
</center>

Meet William Sealy Gosset.

<br/>

**Problem**: A batch of beer should have a fixed [chemical level related to barley]
in order to be of good quality. Can you test a small number of barrels and infer
if the entire batch is of good enough quality?
</div>



##
<center>
<img src="../figs/student-t.png" width = 650>
</center>


##
<center>
<img src="../figs/gosset-plaque.jpg" width = 800>
</center>

<!--
 One version of the origin of the pseudonym is that Gosset’s employer preferred staff to use pen names when publishing scientific papers instead of their real name, so he used the name “Student” to hide his identity. Another version is that Guinness did not want their competitors to know that they were using the t-test to determine the quality of raw material.
-->

## The $t$ distribution {.build}

Used to estimate the mean when you have a small sample drawn from a nearly
normal population.

### Conditions
- Independent observations ($n < 0.1 N$)
- Nearly normal population distribution
    - Check distribution of the sample as a proxy


## $t$ versus normal {.flexbox .vcenter}
```{r tdist, echo = FALSE, fig.height=4.5}
ggplot(NULL, aes(x=x, colour = distribution)) +
  stat_function(data = data.frame(x = -4:4, distribution= factor(1)), 
                fun = dt, args = c(df = 1)) +
  stat_function(data = data.frame(x = -4:4, distribution = factor(2)), 
                fun = dt, args = c(df = 2)) +
  stat_function(data = data.frame(x = -4:4, distribution = factor(3)), 
                fun = dt, args = c(df = 5)) +
  stat_function(data = data.frame(x = -4:4, distribution = factor(4)), 
                fun = dt, args = c(df = 30)) +
  stat_function(data = data.frame(x = -4:4, distribution = factor(5)), 
                fun = dnorm) +
  scale_colour_manual(values = c("orangered4", "orangered3", 
                                 "orangered2", "orangered", "goldenrod"),
                      labels = c("df = 1", "df = 2", "df = 5", "df = 30", "normal"))
```

The $t$ has heavier tails than the normal distribution.


## Degrees of Freedom {.build}
*The number of parameters that are free to vary, without violating any constraint imposed on it*.

### Parameters
$\mu$

<br/>

Since $\bar{x} = \frac{1}{n}\sum_{i = 1}^n x_i$, one of our *observations* is constrained, leaving $n-1$ 
that are free to vary.

$$ df = n - 1$$


## Hypothesis testing {.build}

1. State hypotheses: e.g. $H_0: \mu = \mu_0$ versus $H_A: \mu \ne \mu_0$
2. Check conditions <br>
    - Independent observations  
    - Nearly normal population
3. Compute observed $t$-statistic $$ t_{obs} = \frac{\bar{x} - \mu_0}{s/\sqrt{n}} $$
4. Draw picture to assess where $t_{obs}$ falls in $t_{df = n - 1}$
5. Compute a (two-tailed) $p$-value
6. State conclusion