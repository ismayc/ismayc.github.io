\documentclass{article}
\usepackage{fullpage, amssymb, url, natbib}
\usepackage[colorlinks = true, linkcolor = blue, urlcolor  = blue, citecolor = blue, anchorcolor = blue]{hyperref}

%\pagenumbering{gobble}

\begin{document}

<<echo=FALSE, warning=FALSE, message=FALSE>>=
library(knitr)

library(tidyverse)
library(knitr)
library(stringr)

library(USAboundaries)
library(broom)
library(sp)
library(maptools)

library(nycflights13)
library(babynames)

# Set rounding to 2 digits
options(digits=2)
@



\begin{center}
\textbf{SOC 301 Practice Problems for Exam 2}\\
\textit{Make sure to use your cheatsheets to solve these problems as you prepare.}
\end{center}


\section{``Women and Children First''}
%
%------------------------------------------------------------------------------

You are presented with data on the Titanic disaster of 1912 in a data frame {{\tt Titanic}}, which cross-classifies survival vs death by class, sex, and age. Write down the {{\tt dplyr}} commands that will output a table comparing survival vs death counts for the following three scenarios:

\begin{itemize}
\item[a)] by sex
\item[b)] by sex and class and age
\item[c)] to answer the question if the ``women and children''-first policy of the White Star Line Company (the company that ran the Titanic) held true or not.
\end{itemize}

Note: you don't need to calculate the output table, just write the code that would produce it where the more concise the code the better. Here is what the {{\tt Titanic}} data looks like:\\

<<echo=FALSE, warning=FALSE, message=FALSE, fig.width=8, fig.height=4.5>>=
data(Titanic)
Titanic %>% tbl_df() %>% kable()
@

\newpage
\hspace{1cm}

%------------------------------------------------------------------------------
%
\section{America Runs on Starbucks?}
%
%------------------------------------------------------------------------------

<<echo=FALSE, warning=FALSE, message=FALSE>>=
# Load DD vs SB data, get FIPS codes of counties of interest, and only consider
# these
DD_vs_SB <- read_csv("DD_vs_SB.csv") %>% 
  select(Geo_FIPS, med_inc, sbper1000, per1000) %>% 
  rename(
    FIPS = Geo_FIPS,
    Starbucks = sbper1000,
    `Dunkin Donuts` = per1000
  ) %>% 
  gather(Type, shops_per_1000, -c(FIPS, med_inc))

# FIPS of 6 counties
county_names <- DD_vs_SB$FIPS %>% 
  as.character() %>% 
  str_sub(1,5) %>% 
  unique()
@

A researcher from eastern Massachusetts is a big Starbucks fan. She has a suspicion that Starbucks tend to locate in richer neighborhoods, while this is not the case for Dunkin Donuts. She writes code to scrape the internet for data from all 1024 census tracts (areas where decennial census data are collected) in 6 Eastern Massachusetts counties, specifically Bristol, Essex, Middlesex, Norfolk, Plymouth, and Suffolk counties:

<<echo=FALSE, eval=FALSE, warning=FALSE, message=FALSE, cache=TRUE>>=
# Load counties map, but only for MA
counties_shp <- us_counties()
counties_data <- counties_shp@data
counties_polygon <- tidy(counties_shp, region="geoid")
counties <- left_join(counties_polygon, counties_data, by=c("id"="geoid"))
counties <- counties %>%
  filter(state_name == "Massachusetts")

# Filter county map to just 6 counties of 
counties_interest <- counties %>% 
  filter(id %in% county_names)
@


<<echo=FALSE, out.width="50%">>=
knitr::include_graphics("mass_counties.png")
@


She summarizes her results in the following graphic:

\begin{center}
<<echo=FALSE, warning=FALSE, message=FALSE, fig.width=8*1.1, fig.height=3.5*1.1>>=
ggplot(DD_vs_SB, aes(x=med_inc, y=shops_per_1000)) +
  geom_point(aes(col=Type)) + 
  facet_wrap(~Type) +
 # geom_smooth(method="lm", se=FALSE) + 
  labs(x="Median Household Income", y="# of shops per 1000 people", 
       title="Coffee/Cafe Comparison in Eastern MA") +
  scale_color_manual(values=c("orange", "forestgreen"))
@
\end{center}

\begin{itemize}
\item[a)] Sketch out (in tidy data format) the data set needed to make this graphic. 
\item[b)] Write the {{\tt ggplot}} code that generates this graphic. Be sure to write your code so that the various layers (the components you add to the base {{\tt ggplot()}} call with {{+}} signs) are clear.  (The \verb+scale_color_manual+ function can specify colors.)
\item[c)] Name two improvements that can be made to this graphic.
\item[d)] Does this evidence support or contradict the researcher's suspicion? Why?
\end{itemize}

\newpage

%------------------------------------------------------------------------------
%
\section{NYC Flights}
%
%------------------------------------------------------------------------------

Recall the {{\tt airports}}, {{\tt planes}}, {{\tt flights}}, {{\tt weather}}, and {{\tt airlines}} data sets in the {{\tt nycflights13}} data set and that we saw the following graphic of the relationships between these data sets in the textbook: 

\begin{center}
\includegraphics[width=4in]{relational-nycflights.png}
\end{center}

\noindent Also, consider the following R output:

<<echo=TRUE, warning=FALSE, message=FALSE, fig.width=8*1.1, fig.height=3.5*1.1>>=
names(airports)
names(planes)
names(flights)
names(weather)
names(airlines)
@

\newpage
\begin{itemize}
\item[a)] Which data sets are you going to need to compute the distance covered by all
flights leaving New York City?
\item[b)] Write the code that will output a table presenting the median departure delay of all flights for each airline leaving Newark (airport code {{\tt EWR}}) .
\item[c)] Write the extra lines of code that will output a table presenting the median departure delay of all flights for each airline leaving Newark, but this time in reverse alphabetical order.
\item[d)] Name a graphic that would best show all the information contained in the table in part b).
\item[e)] Write the code that will tabulate the mean humidity level
recorded for all flights leaving New York City in July 2013. 
\end{itemize}

\newpage
\hspace{1cm}

%------------------------------------------------------------------------------
%
\section{Unisex Names... Revisited}
%
%------------------------------------------------------------------------------

Write the code that is going to generate an appropriate visualization to compare the trends in the ``unisex''iness (not a measure of gender ambiguous sexiness, but rather the degree to which a name is used by both sexes) of the names ``Casey'' and ``Riley'' from 1950 to 2014. As a hint, here are the first 10 rows of the {{\tt babynames}} data set.\\

<<echo=FALSE, warning=FALSE, message=FALSE, fig.width=8*1.1, fig.height=3.5*1.1>>=
babynames %>% slice(1:10) %>% kable()
@

\newpage
\hspace{1cm}

%------------------------------------------------------------------------------
%
\section{Inference Basics}
%
%------------------------------------------------------------------------------

This example involves thinking about county level data on the percentage of black residents.  All that is collected is a random representative sample of 200 US counties.  Describe how the process of bootstrapping could be used to create a plot and a range of possible values for the percentage of black residents, on average, by county throughout the entire US.

\begin{itemize}
  \item Layout what the tidy data set would look like for this sample of 200 counties.
  \item You should carefully lay out each step of the bootstrapping process being as specific as possible.  For example, you should be clear about the size of each sample and how many times you are repeating the process.
  \item Additionally, you should sketch a plot (free hand) of what the bootstrap distribution might look like and how one could use the distribution to help solve the problem.  (Your numbers may not necessarily be correct, but it's important to get a sense of what the plot might look like.)
\end{itemize}

You should be as thorough as possible.  If you can explain the bootstrapping process in this circumstance, you should be able to explain the process in any similar circumstance.
  





\end{document}